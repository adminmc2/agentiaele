# üöÄ ARQUITECTURA ESCALABLE PARA M√öLTIPLES USUARIOS

## ‚ö†Ô∏è PROBLEMAS DE LA ARQUITECTURA ACTUAL

### **‚ùå Limitaciones Cr√≠ticas:**

```
PROBLEMA 1: LLAMADAS S√çNCRONAS A DEEPSEEK
- Cada usuario espera su turno
- Si 100 usuarios solicitan correcci√≥n al mismo tiempo ‚Üí colapso
- No hay cola de procesamiento
- No hay l√≠mite de rate

PROBLEMA 2: MEMORIA EN RAM
- AgentMemory usa Map() en memoria local
- Se pierde al reiniciar servidor
- No se comparte entre instancias (si escalas horizontalmente)
- Crece indefinidamente

PROBLEMA 3: CACHE LOCAL
- Cache no persistente
- No compartido entre servidores
- Se duplica entre instancias

PROBLEMA 4: SIN RATE LIMITING
- Un usuario puede hacer 1000 requests/minuto
- Costos de API sin control
- Puede agotar l√≠mites de DeepSeek

PROBLEMA 5: SIN MANEJO DE ERRORES
- Si DeepSeek falla ‚Üí usuario ve error
- No hay reintentos
- No hay fallback

PROBLEMA 6: COSTO DESCONTROLADO
- Cada request es una llamada nueva a IA
- Sin agregaci√≥n de requests similares
- Sin optimizaci√≥n de prompts
```

---

## ‚úÖ ARQUITECTURA ESCALABLE - PROPUESTA MEJORADA

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    USUARIOS (1-10,000+)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              NETLIFY FRONTEND (Edge Functions)                ‚îÇ
‚îÇ  ‚Ä¢ Rate Limiting por usuario                                  ‚îÇ
‚îÇ  ‚Ä¢ Validaci√≥n de requests                                     ‚îÇ
‚îÇ  ‚Ä¢ Cache de respuestas est√°ticas                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  SUPABASE (API Layer)                         ‚îÇ
‚îÇ  ‚Ä¢ Authentication                                             ‚îÇ
‚îÇ  ‚Ä¢ Row Level Security                                         ‚îÇ
‚îÇ  ‚Ä¢ Database (PostgreSQL)                                      ‚îÇ
‚îÇ  ‚Ä¢ Storage                                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            SUPABASE EDGE FUNCTIONS (Backend)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ  AGENT WORKER (Serverless)                 ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Procesa requests de agentes             ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Rate limiting interno                   ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Cola de prioridades                     ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Reintentos autom√°ticos                  ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ            ‚îÇ            ‚îÇ
        ‚ñº            ‚ñº            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   REDIS     ‚îÇ ‚îÇ POSTGRES ‚îÇ ‚îÇ  DEEPSEEK   ‚îÇ
‚îÇ   CACHE     ‚îÇ ‚îÇ  QUEUE   ‚îÇ ‚îÇ     API     ‚îÇ
‚îÇ  (Upstash)  ‚îÇ ‚îÇ (Supabase‚îÇ ‚îÇ  (con l√≠mites‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Ä¢ Cache global  ‚Ä¢ Cola de     ‚Ä¢ Rate limited
  ‚Ä¢ TTL por tipo   tareas       ‚Ä¢ Retry logic
  ‚Ä¢ Compartido    ‚Ä¢ Prioridades  ‚Ä¢ Fallback
```

---

## üèóÔ∏è COMPONENTES CLAVE

### **1. SISTEMA DE COLA (PostgreSQL + Supabase)**

**Tabla: agent_queue**

```sql
CREATE TABLE agent_queue (
  id BIGSERIAL PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) NOT NULL,
  agent_type VARCHAR NOT NULL, -- 'corrector', 'translator', etc.
  request_data JSONB NOT NULL,
  priority INTEGER DEFAULT 5, -- 1 (alta) a 10 (baja)
  status VARCHAR DEFAULT 'pending', -- 'pending', 'processing', 'completed', 'failed'
  result JSONB,
  error_message TEXT,
  retry_count INTEGER DEFAULT 0,
  max_retries INTEGER DEFAULT 3,
  created_at TIMESTAMP DEFAULT NOW(),
  started_at TIMESTAMP,
  completed_at TIMESTAMP,
  expires_at TIMESTAMP DEFAULT NOW() + INTERVAL '5 minutes',
  INDEX idx_status_priority (status, priority, created_at)
);
```

**Worker que procesa la cola:**

```javascript
// supabase/functions/agent-worker/index.ts
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const BATCH_SIZE = 10 // Procesar 10 requests a la vez
const POLL_INTERVAL = 2000 // Revisar cola cada 2 segundos

serve(async (req) => {
  const supabase = createClient(
    Deno.env.get('SUPABASE_URL'),
    Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')
  )

  while (true) {
    try {
      // Obtener siguiente batch de tareas pendientes
      const { data: tasks, error } = await supabase
        .from('agent_queue')
        .select('*')
        .eq('status', 'pending')
        .lt('expires_at', new Date().toISOString())
        .order('priority', { ascending: true })
        .order('created_at', { ascending: true })
        .limit(BATCH_SIZE)

      if (error || !tasks || tasks.length === 0) {
        await new Promise(resolve => setTimeout(resolve, POLL_INTERVAL))
        continue
      }

      // Procesar en paralelo con l√≠mite
      await Promise.all(
        tasks.map(task => processTask(task, supabase))
      )

    } catch (error) {
      console.error('Worker error:', error)
      await new Promise(resolve => setTimeout(resolve, POLL_INTERVAL))
    }
  }
})

async function processTask(task, supabase) {
  try {
    // Marcar como procesando
    await supabase
      .from('agent_queue')
      .update({
        status: 'processing',
        started_at: new Date().toISOString()
      })
      .eq('id', task.id)

    // Procesar seg√∫n tipo de agente
    const result = await executeAgent(
      task.agent_type,
      task.request_data
    )

    // Guardar resultado
    await supabase
      .from('agent_queue')
      .update({
        status: 'completed',
        result: result,
        completed_at: new Date().toISOString()
      })
      .eq('id', task.id)

    // Notificar al usuario (opcional)
    await notifyUser(task.user_id, result)

  } catch (error) {
    // Manejar error y reintentar si es necesario
    const shouldRetry = task.retry_count < task.max_retries

    if (shouldRetry) {
      await supabase
        .from('agent_queue')
        .update({
          status: 'pending',
          retry_count: task.retry_count + 1,
          error_message: error.message
        })
        .eq('id', task.id)
    } else {
      await supabase
        .from('agent_queue')
        .update({
          status: 'failed',
          error_message: error.message,
          completed_at: new Date().toISOString()
        })
        .eq('id', task.id)
    }
  }
}
```

---

### **2. RATE LIMITING (Supabase + Redis)**

**Tabla: rate_limits**

```sql
CREATE TABLE rate_limits (
  id BIGSERIAL PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) NOT NULL,
  endpoint VARCHAR NOT NULL, -- 'check_answer', 'translate', etc.
  request_count INTEGER DEFAULT 1,
  window_start TIMESTAMP DEFAULT NOW(),
  window_end TIMESTAMP,
  is_blocked BOOLEAN DEFAULT false,
  UNIQUE(user_id, endpoint, window_start)
);

-- Funci√≥n para verificar rate limit
CREATE OR REPLACE FUNCTION check_rate_limit(
  p_user_id UUID,
  p_endpoint VARCHAR,
  p_max_requests INTEGER DEFAULT 10,
  p_window_minutes INTEGER DEFAULT 1
) RETURNS BOOLEAN AS $$
DECLARE
  v_count INTEGER;
  v_window_start TIMESTAMP;
BEGIN
  v_window_start := NOW() - (p_window_minutes || ' minutes')::INTERVAL;

  SELECT COALESCE(SUM(request_count), 0)
  INTO v_count
  FROM rate_limits
  WHERE user_id = p_user_id
    AND endpoint = p_endpoint
    AND window_start >= v_window_start;

  IF v_count >= p_max_requests THEN
    RETURN FALSE;
  END IF;

  INSERT INTO rate_limits (user_id, endpoint, request_count, window_start)
  VALUES (p_user_id, p_endpoint, 1, NOW())
  ON CONFLICT (user_id, endpoint, window_start)
  DO UPDATE SET request_count = rate_limits.request_count + 1;

  RETURN TRUE;
END;
$$ LANGUAGE plpgsql;
```

**Implementaci√≥n en frontend:**

```javascript
// src/services/rateLimiter.js
export class RateLimiter {
  constructor(supabase) {
    this.supabase = supabase
    this.limits = {
      check_answer: { max: 20, window: 1 }, // 20 por minuto
      translate: { max: 30, window: 1 },
      generate_examples: { max: 10, window: 5 },
      ask_teacher: { max: 50, window: 1 }
    }
  }

  async checkLimit(userId, endpoint) {
    const limit = this.limits[endpoint] || { max: 10, window: 1 }

    const { data, error } = await this.supabase.rpc('check_rate_limit', {
      p_user_id: userId,
      p_endpoint: endpoint,
      p_max_requests: limit.max,
      p_window_minutes: limit.window
    })

    if (error) {
      console.error('Rate limit check error:', error)
      return true // Permitir en caso de error
    }

    if (!data) {
      throw new Error(`Rate limit excedido para ${endpoint}. Espera ${limit.window} minuto(s).`)
    }

    return true
  }
}
```

---

### **3. CACHE DISTRIBUIDO (Upstash Redis o Supabase)**

**Opci√≥n A: Upstash Redis (Recomendado)**

```javascript
// src/services/cacheService.js
import { Redis } from '@upstash/redis'

export class CacheService {
  constructor() {
    this.redis = new Redis({
      url: process.env.UPSTASH_REDIS_URL,
      token: process.env.UPSTASH_REDIS_TOKEN
    })

    // TTL por tipo de contenido
    this.ttl = {
      translation: 86400,      // 24 horas
      correction: 3600,        // 1 hora
      evaluation: 3600,        // 1 hora
      examples: 7200,          // 2 horas
      teacher_response: 1800   // 30 minutos
    }
  }

  /**
   * Generar clave de cache
   */
  generateKey(type, data) {
    const hash = this.simpleHash(JSON.stringify(data))
    return `${type}:${hash}`
  }

  /**
   * Obtener del cache
   */
  async get(type, data) {
    const key = this.generateKey(type, data)
    const cached = await this.redis.get(key)

    if (cached) {
      console.log(`‚úÖ Cache HIT: ${key}`)
      return JSON.parse(cached)
    }

    console.log(`‚ùå Cache MISS: ${key}`)
    return null
  }

  /**
   * Guardar en cache
   */
  async set(type, data, result) {
    const key = this.generateKey(type, data)
    const ttl = this.ttl[type] || 3600

    await this.redis.setex(key, ttl, JSON.stringify(result))
    console.log(`üíæ Cached: ${key} (TTL: ${ttl}s)`)
  }

  /**
   * Invalidar cache por patr√≥n
   */
  async invalidate(pattern) {
    const keys = await this.redis.keys(pattern)
    if (keys.length > 0) {
      await this.redis.del(...keys)
      console.log(`üóëÔ∏è Invalidated ${keys.length} keys`)
    }
  }

  /**
   * Hash simple
   */
  simpleHash(str) {
    let hash = 0
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i)
      hash = ((hash << 5) - hash) + char
      hash = hash & hash
    }
    return Math.abs(hash).toString(36)
  }

  /**
   * Estad√≠sticas de cache
   */
  async getStats() {
    const info = await this.redis.info()
    return {
      hits: info.keyspace_hits || 0,
      misses: info.keyspace_misses || 0,
      hitRate: info.keyspace_hits / (info.keyspace_hits + info.keyspace_misses) * 100
    }
  }
}
```

**Opci√≥n B: Cache en PostgreSQL (m√°s simple)**

```sql
CREATE TABLE cache_store (
  key VARCHAR PRIMARY KEY,
  value JSONB NOT NULL,
  type VARCHAR NOT NULL,
  expires_at TIMESTAMP NOT NULL,
  created_at TIMESTAMP DEFAULT NOW(),
  INDEX idx_expires (expires_at)
);

-- Limpiar cache expirado (ejecutar peri√≥dicamente)
CREATE OR REPLACE FUNCTION clean_expired_cache()
RETURNS void AS $$
BEGIN
  DELETE FROM cache_store WHERE expires_at < NOW();
END;
$$ LANGUAGE plpgsql;
```

---

### **4. SERVICIO DE AGENTES MEJORADO**

```javascript
// src/services/agentService.js (VERSI√ìN ESCALABLE)
import { createClient } from '@supabase/supabase-js'
import { CacheService } from './cacheService.js'
import { RateLimiter } from './rateLimiter.js'

export class AgentService {
  constructor() {
    this.supabase = createClient(
      process.env.SUPABASE_URL,
      process.env.SUPABASE_ANON_KEY
    )
    this.cache = new CacheService()
    this.rateLimiter = new RateLimiter(this.supabase)
  }

  /**
   * Comprobar respuesta (con cola)
   */
  async checkActivityAnswer(activity, userAnswer, userId, options = {}) {
    // 1. Verificar rate limit
    await this.rateLimiter.checkLimit(userId, 'check_answer')

    // 2. Verificar cache
    const cacheKey = {
      activity_id: activity.id,
      answer: userAnswer
    }

    const cached = await this.cache.get('correction', cacheKey)
    if (cached && !options.skipCache) {
      return cached
    }

    // 3. Agregar a cola
    const { data: queueItem, error } = await this.supabase
      .from('agent_queue')
      .insert({
        user_id: userId,
        agent_type: 'check_answer',
        request_data: {
          activity: activity,
          user_answer: userAnswer,
          options: options
        },
        priority: options.priority || 5
      })
      .select()
      .single()

    if (error) throw error

    // 4. Esperar resultado (polling o realtime)
    const result = await this.waitForResult(queueItem.id)

    // 5. Guardar en cache
    await this.cache.set('correction', cacheKey, result)

    return result
  }

  /**
   * Esperar resultado de la cola
   */
  async waitForResult(queueId, timeout = 30000) {
    const startTime = Date.now()

    while (Date.now() - startTime < timeout) {
      const { data, error } = await this.supabase
        .from('agent_queue')
        .select('status, result, error_message')
        .eq('id', queueId)
        .single()

      if (error) throw error

      if (data.status === 'completed') {
        return data.result
      }

      if (data.status === 'failed') {
        throw new Error(data.error_message || 'Processing failed')
      }

      // Esperar antes de siguiente check
      await new Promise(resolve => setTimeout(resolve, 1000))
    }

    throw new Error('Request timeout')
  }

  /**
   * Alternativa: Usar Realtime de Supabase (mejor UX)
   */
  async waitForResultRealtime(queueId, timeout = 30000) {
    return new Promise((resolve, reject) => {
      const timer = setTimeout(() => {
        channel.unsubscribe()
        reject(new Error('Request timeout'))
      }, timeout)

      const channel = this.supabase
        .channel(`queue:${queueId}`)
        .on(
          'postgres_changes',
          {
            event: 'UPDATE',
            schema: 'public',
            table: 'agent_queue',
            filter: `id=eq.${queueId}`
          },
          (payload) => {
            const record = payload.new

            if (record.status === 'completed') {
              clearTimeout(timer)
              channel.unsubscribe()
              resolve(record.result)
            }

            if (record.status === 'failed') {
              clearTimeout(timer)
              channel.unsubscribe()
              reject(new Error(record.error_message))
            }
          }
        )
        .subscribe()
    })
  }

  /**
   * Traducci√≥n con cache agresivo
   */
  async translate(text, targetLang, userId) {
    await this.rateLimiter.checkLimit(userId, 'translate')

    const cacheKey = { text, target_lang: targetLang }
    const cached = await this.cache.get('translation', cacheKey)

    if (cached) return cached

    // Agregar a cola con prioridad alta
    const result = await this.queueRequest({
      user_id: userId,
      agent_type: 'translate',
      request_data: { text, target_lang: targetLang },
      priority: 3 // Alta prioridad
    })

    await this.cache.set('translation', cacheKey, result)
    return result
  }

  /**
   * M√©todo gen√©rico para agregar a cola
   */
  async queueRequest(data) {
    const { data: queueItem, error } = await this.supabase
      .from('agent_queue')
      .insert(data)
      .select()
      .single()

    if (error) throw error

    return await this.waitForResultRealtime(queueItem.id)
  }
}
```

---

### **5. OPTIMIZACI√ìN DE COSTOS**

**Tabla: api_usage**

```sql
CREATE TABLE api_usage (
  id BIGSERIAL PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id),
  agent_type VARCHAR NOT NULL,
  tokens_used INTEGER NOT NULL,
  cost_usd DECIMAL(10, 6),
  cached BOOLEAN DEFAULT false,
  created_at TIMESTAMP DEFAULT NOW(),
  INDEX idx_user_date (user_id, created_at)
);

-- Vista de costos por usuario
CREATE VIEW user_costs AS
SELECT
  user_id,
  DATE_TRUNC('day', created_at) as date,
  SUM(tokens_used) as total_tokens,
  SUM(cost_usd) as total_cost,
  COUNT(*) as total_requests,
  COUNT(*) FILTER (WHERE cached = true) as cached_requests
FROM api_usage
GROUP BY user_id, DATE_TRUNC('day', created_at);
```

**Sistema de alertas de costos:**

```javascript
// supabase/functions/cost-monitor/index.ts
async function checkCostLimits() {
  const { data: users } = await supabase
    .from('user_costs')
    .select('*')
    .gte('date', new Date().toISOString().split('T')[0])

  for (const user of users) {
    // Usuario gratuito: m√°ximo $1/d√≠a
    if (user.total_cost > 1.0 && !user.is_premium) {
      await throttleUser(user.user_id)
      await notifyUser(user.user_id, 'L√≠mite diario alcanzado')
    }

    // Usuario premium: m√°ximo $10/d√≠a
    if (user.total_cost > 10.0 && user.is_premium) {
      await notifyAdmin(user.user_id, 'Usuario excede l√≠mite premium')
    }
  }
}
```

---

### **6. BATCH PROCESSING (Optimizaci√≥n)**

**Procesar m√∫ltiples requests similares juntos:**

```javascript
// supabase/functions/batch-processor/index.ts
async function processBatch() {
  // Buscar requests de traducci√≥n pendientes al mismo idioma
  const { data: batch } = await supabase
    .from('agent_queue')
    .select('*')
    .eq('agent_type', 'translate')
    .eq('status', 'pending')
    .limit(50)

  // Agrupar por idioma objetivo
  const grouped = {}
  for (const item of batch) {
    const lang = item.request_data.target_lang
    if (!grouped[lang]) grouped[lang] = []
    grouped[lang].push(item)
  }

  // Procesar cada grupo en una sola llamada
  for (const [lang, items] of Object.entries(grouped)) {
    const texts = items.map(i => i.request_data.text)

    // Una sola llamada para todos
    const translations = await translateBatch(texts, lang)

    // Actualizar resultados
    for (let i = 0; i < items.length; i++) {
      await supabase
        .from('agent_queue')
        .update({
          status: 'completed',
          result: { translation: translations[i] }
        })
        .eq('id', items[i].id)
    }
  }
}
```

---

### **7. FALLBACK Y RESILIENCIA**

```javascript
// src/services/resilientAgent.js
export class ResilientAgent {
  constructor(primaryAPI, fallbackAPI) {
    this.primary = primaryAPI
    this.fallback = fallbackAPI
    this.circuitBreaker = {
      failures: 0,
      threshold: 5,
      timeout: 60000, // 1 minuto
      isOpen: false,
      openedAt: null
    }
  }

  async execute(request) {
    // Circuit breaker abierto: usar fallback directamente
    if (this.isCircuitOpen()) {
      console.log('‚ö†Ô∏è Circuit breaker OPEN, usando fallback')
      return await this.fallback.execute(request)
    }

    try {
      // Intentar con API primaria
      const result = await this.executeWithRetry(
        () => this.primary.execute(request),
        3
      )

      // Reset circuit breaker en √©xito
      this.circuitBreaker.failures = 0

      return result

    } catch (error) {
      console.error('Primary API failed:', error)

      // Incrementar contador de fallos
      this.circuitBreaker.failures++

      // Abrir circuit breaker si excede threshold
      if (this.circuitBreaker.failures >= this.circuitBreaker.threshold) {
        this.openCircuitBreaker()
      }

      // Usar fallback
      try {
        return await this.fallback.execute(request)
      } catch (fallbackError) {
        throw new Error('Both primary and fallback failed')
      }
    }
  }

  async executeWithRetry(fn, maxRetries) {
    for (let i = 0; i < maxRetries; i++) {
      try {
        return await fn()
      } catch (error) {
        if (i === maxRetries - 1) throw error

        // Backoff exponencial
        const delay = Math.pow(2, i) * 1000
        await new Promise(resolve => setTimeout(resolve, delay))
      }
    }
  }

  isCircuitOpen() {
    if (!this.circuitBreaker.isOpen) return false

    // Verificar si debe cerrarse
    const elapsed = Date.now() - this.circuitBreaker.openedAt
    if (elapsed > this.circuitBreaker.timeout) {
      this.closeCircuitBreaker()
      return false
    }

    return true
  }

  openCircuitBreaker() {
    console.log('üî¥ Circuit breaker OPENED')
    this.circuitBreaker.isOpen = true
    this.circuitBreaker.openedAt = Date.now()
  }

  closeCircuitBreaker() {
    console.log('üü¢ Circuit breaker CLOSED')
    this.circuitBreaker.isOpen = false
    this.circuitBreaker.failures = 0
  }
}
```

---

## üìä CAPACIDAD Y COSTOS

### **Estimaci√≥n de Capacidad**

```
CON ARQUITECTURA ESCALABLE:

‚Ä¢ Sin cola:
  - 10 usuarios concurrentes = OK
  - 100 usuarios concurrentes = COLAPSO ‚ùå

‚Ä¢ Con cola + cache:
  - 10 usuarios concurrentes = OK ‚úÖ
  - 100 usuarios concurrentes = OK ‚úÖ
  - 1,000 usuarios concurrentes = OK ‚úÖ
  - 10,000 usuarios concurrentes = OK con ajustes ‚úÖ

MEJORAS DE CACHE:
‚Ä¢ Cache hit rate 60-80%
‚Ä¢ Reduce costos en 60-80%
‚Ä¢ Reduce latencia promedio 90%

EJEMPLO:
Sin cache:
  - 1000 requests/d√≠a √ó 1000 usuarios = 1M requests
  - 1M √ó $0.0001 = $100/d√≠a = $3,000/mes

Con cache (70% hit rate):
  - 300K requests reales
  - 300K √ó $0.0001 = $30/d√≠a = $900/mes
  - AHORRO: $2,100/mes (70%)
```

---

## üõ†Ô∏è PLAN DE MIGRACI√ìN

### **Fase 1: Preparaci√≥n (1 d√≠a)**
```bash
1. Crear tablas de cola y rate limiting
2. Configurar Upstash Redis
3. Crear Edge Functions b√°sicas
```

### **Fase 2: Implementar Cola (2 d√≠as)**
```bash
1. Crear agent-worker function
2. Migrar checkAnswer a cola
3. Implementar polling/realtime
4. Testing con m√∫ltiples usuarios
```

### **Fase 3: Cache Distribuido (1 d√≠a)**
```bash
1. Integrar Upstash Redis
2. Migrar cache a Redis
3. Implementar invalidaci√≥n
```

### **Fase 4: Rate Limiting (1 d√≠a)**
```bash
1. Implementar rate limiter
2. Agregar por endpoint
3. UI para mostrar l√≠mites
```

### **Fase 5: Monitoring (1 d√≠a)**
```bash
1. Dashboard de m√©tricas
2. Alertas de costos
3. Health checks
```

---

## üéØ CONFIGURACI√ìN RECOMENDADA

```javascript
// config/scaling.js
export const SCALING_CONFIG = {
  // Rate limits por tipo de usuario
  rateLimits: {
    free: {
      check_answer: { max: 10, window: 60 }, // 10/min
      translate: { max: 20, window: 60 },
      examples: { max: 5, window: 60 },
      daily_total: 100
    },
    premium: {
      check_answer: { max: 50, window: 60 },
      translate: { max: 100, window: 60 },
      examples: { max: 30, window: 60 },
      daily_total: 1000
    },
    superadmin: {
      // Sin l√≠mites
      unlimited: true
    }
  },

  // Configuraci√≥n de cola
  queue: {
    batchSize: 10,
    pollInterval: 2000, // ms
    maxRetries: 3,
    timeout: 30000, // ms
    priorities: {
      high: 1,
      normal: 5,
      low: 9
    }
  },

  // Cache TTL
  cache: {
    translation: 86400,    // 24h
    correction: 3600,      // 1h
    evaluation: 3600,      // 1h
    examples: 7200,        // 2h
    teacher: 1800          // 30min
  },

  // L√≠mites de costo
  costLimits: {
    free: { daily: 0.10, monthly: 2.00 },
    premium: { daily: 5.00, monthly: 100.00 }
  }
}
```

---

## ‚úÖ RESUMEN

### **La arquitectura escalable incluye:**

‚úÖ **Sistema de cola** ‚Üí Procesa requests de forma ordenada
‚úÖ **Rate limiting** ‚Üí Previene abuso y controla costos
‚úÖ **Cache distribuido** ‚Üí Reduce costos 60-80%
‚úÖ **Batch processing** ‚Üí Optimiza llamadas a IA
‚úÖ **Circuit breaker** ‚Üí Resiliencia ante fallos
‚úÖ **Monitoring** ‚Üí Alertas y m√©tricas
‚úÖ **Cost control** ‚Üí L√≠mites por usuario

### **Puede manejar:**
- ‚úÖ 10,000+ usuarios concurrentes
- ‚úÖ Millones de requests/d√≠a
- ‚úÖ Costos controlados y predecibles
- ‚úÖ 99.9% uptime con fallbacks

### **Costo estimado:**
- Sin optimizaci√≥n: $3,000/mes
- Con optimizaci√≥n: $900/mes
- **Ahorro: 70%**

---

**¬øQuieres que implemente esta arquitectura escalable?** üöÄ
